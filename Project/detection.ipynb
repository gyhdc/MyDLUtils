{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from utils import datasets\n",
    "from utils import utils\n",
    "from utils import train_val,train_val_for_det\n",
    "from utils import net #网络文件于此\n",
    "from utils import metrics\n",
    "import warnings\n",
    "# 完全禁用警告\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import Config,Logs,BestSelector\n",
    "config=utils.Config(\n",
    "    dataset_sep=[\n",
    "        0.82,0.17,0.01          \n",
    "        ],\n",
    "    resize_size=(128,128),#图像尺寸\n",
    "    batch_size=2,\n",
    "    lr=0.0007,\n",
    "    epochs=5,#epoch轮数\n",
    "    hidden_size=256,\n",
    "    optim=\"Adam\",\n",
    "    momentum=0.9,\n",
    "    weight_decay=1e-4,\n",
    "    seed=42,\n",
    "    mean= [0.50638 ,0.49962538 ,0.45205265],\n",
    "    std=[0.23568255 ,0.24141274 ,0.25167742],\n",
    "    AMP=True,\n",
    "    checkpoint_interval=0.25,#只保存4个模型\n",
    "    source_dir=r\"Cifar-10\",#原始数据集，每个分类一个文件夹，每个文件夹里包含多个图片\n",
    "    data_path=r\"data\\PascalVOC\",#项目数据集\n",
    "    data_crop_rate=0.25,#只使用0.25\n",
    "    # classes=[\"Apple\",\"Carambola\",\"Pear\",\"Plum\",\"Tomatoes\"],\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载 Pascal VOC 数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始训练集大小：8655\n",
      "原始验证集大小：2885\n",
      "原始测试集大小：5823\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torchvision\n",
    "train_val_dataset = torchvision.datasets.VOCDetection(\n",
    "    root=config.data_path, \n",
    "    year='2012',\n",
    "    image_set='trainval',\n",
    "    # download=True, \n",
    "    transform=datasets.get_transform(\n",
    "        chance=\"val\",\n",
    "        resize_size=config.resize_size,\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    ")\n",
    "train_dataset,val_dataset=datasets.get_parts_of_datasets(train_val_dataset,rate=0.75,only_train=False)#训练验证3-1开\n",
    "\n",
    "test_dataset = torchvision.datasets.VOCDetection(\n",
    "        root=config.data_path,\n",
    "        year='2012',\n",
    "        image_set='val',\n",
    "        # download=True,\n",
    "        \n",
    "        transform=datasets.get_transform(\n",
    "            chance=\"val\",\n",
    "            resize_size=config.resize_size,\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "))\n",
    "print(f\"原始训练集大小：{len(train_dataset)}\")\n",
    "print(f\"原始验证集大小：{len(val_dataset)}\")\n",
    "print(f\"原始测试集大小：{len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### load数据集，并根据数据量进行裁剪。原数据集较大，本身为学习项目只取其中1/4数据进行训练测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "本次训练用训练集大小：2163\n",
      "本次训练用验证集大小：721\n",
      "本次测试用测试集大小：1455\n",
      "tarin_dataloader加载完毕, 1081个batch, batch大小为2\n",
      "val_dataloader  加载完毕, 361个batch, batch大小为2\n",
      "test_dataloader 加载完毕, 728个batch, batch大小为2\n"
     ]
    }
   ],
   "source": [
    "from utils import datasets_for_det\n",
    "crop_rate=config.data_crop_rate\n",
    "train_dataset_crop=datasets.get_parts_of_datasets(train_dataset,crop_rate)\n",
    "val_dataset_crop=datasets.get_parts_of_datasets(val_dataset,crop_rate)\n",
    "test_dataset_crop=datasets.get_parts_of_datasets(test_dataset,crop_rate)\n",
    "train_dataset_size=len(train_dataset_crop)\n",
    "val_dataset_size=len(val_dataset_crop)\n",
    "test_dataset_size=len(test_dataset_crop)\n",
    "\n",
    "print(f\"本次训练用训练集大小：{len(train_dataset_crop)}\")\n",
    "print(f\"本次训练用验证集大小：{len(val_dataset_crop)}\")\n",
    "print(f\"本次测试用测试集大小：{len(test_dataset_crop)}\")\n",
    "collate_fn=datasets_for_det.PascalVOC.collate_fn\n",
    "train_loader=DataLoader(train_dataset_crop,batch_size=config.batch_size,shuffle=True,drop_last=True,collate_fn=collate_fn)\n",
    "val_loader=DataLoader(val_dataset_crop,batch_size=config.batch_size,shuffle=False,collate_fn=collate_fn)\n",
    "test_loader=DataLoader(test_dataset_crop,batch_size=config.batch_size,shuffle=False,collate_fn=collate_fn)\n",
    "\n",
    "print(f\"tarin_dataloader加载完毕, {len(train_loader)}个batch, batch大小为{config.batch_size}\")\n",
    "print(f\"val_dataloader  加载完毕, {len(val_loader)}个batch, batch大小为{config.batch_size}\")\n",
    "print(f\"test_dataloader 加载完毕, {len(test_loader)}个batch, batch大小为{config.batch_size}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 记录本次训练和测试用的数据量，还有数据样本信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "torch.Size([1, 4])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "#查看数据加载情况\n",
    "for images, targets in val_loader:\n",
    "    # images = [img.to(device) for img in images]\n",
    "    images = torch.stack(images, dim=0).to(config.device)#一batch的图像[B,C,H,W]\n",
    "    targets = [{k: v.to(config.device) for k, v in t.items()} for t in targets] #一batch的['boxes', 'labels']\n",
    "    print(len(targets))\n",
    "    print(targets[0][\"boxes\"].shape)#[num,4]第i个图像有 num个box\n",
    "    print(targets[0][\"labels\"].shape)#[num]num个box对应的分类\n",
    "    #output = {\"boxes\": reg_preds, \"scores\": scores, \"labels\": labels}\n",
    "    config.update(\n",
    "        inputs_shape=images.shape,#[B,C,H,W]\n",
    "        # classes=train_val_dataset.classes,#原始数据集保留classes\n",
    "    )\n",
    "    break\n",
    "\n",
    "    \n",
    "config.update(\n",
    "    train_datasize=train_dataset_size,\n",
    "    val_datasetsize=val_dataset_size,\n",
    "    test_datasetsize=test_dataset_size,\n",
    "    # classes=train_val_dataset.classes,#原始数据集保留classes\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "参数数量：41755286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warm up ....: 100%|██████████| 100/100 [00:11<00:00,  8.85it/s]\n",
      "Testing ...: 100%|██████████| 300/300 [00:32<00:00,  9.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "推理一个batch的时间：0.10713303428649902 s\n",
      "inference_time:0.10713303428649902 s\n",
      "parameters_num:41755286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dataset_sep : [0.82, 0.17, 0.01] \n",
       "resize_size : (128, 128) \n",
       "batch_size : 2 \n",
       "lr : 0.0007 \n",
       "epochs : 5 \n",
       "hidden_size : 256 \n",
       "optim : Adam \n",
       "momentum : 0.9 \n",
       "weight_decay : 0.0001 \n",
       "seed : 42 \n",
       "mean : [0.50638, 0.49962538, 0.45205265] \n",
       "std : [0.23568255, 0.24141274, 0.25167742] \n",
       "AMP : True \n",
       "checkpoint_interval : 0.25 \n",
       "source_dir : Cifar-10 \n",
       "data_path : data\\PascalVOC \n",
       "data_crop_rate : 0.25 \n",
       "device : cuda \n",
       "inputs_shape : torch.Size([2, 3, 128, 128]) \n",
       "train_datasize : 2163 \n",
       "val_datasetsize : 721 \n",
       "test_datasetsize : 1455 \n",
       "network : FasterRCNN \n",
       "inference_time : 0.10713303428649902 \n",
       "parameters_num : 41755286 "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import models\n",
    "def get_pretrained(config=config):\n",
    "    '''\n",
    "        获取预训练模型\n",
    "        @param config: 配置文件\n",
    "        @return: 预训练模型\n",
    "    '''\n",
    "    \n",
    "    model=models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    return model.to(config.device)\n",
    "\n",
    "test_model=get_pretrained()\n",
    "measurer=metrics.ModelMeasurer(test_model)\n",
    "unit=1\n",
    "parameters_num,inference_time=measurer.simply_check_model(input_shape=config.inputs_shape)\n",
    "print(f\"inference_time:{inference_time} s\")\n",
    "print(f\"parameters_num:{parameters_num}\")\n",
    "config.update(\n",
    "    network=test_model.__class__.__name__,\n",
    "    inference_time=inference_time,\n",
    "    parameters_num=parameters_num,\n",
    ")\n",
    "config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练检测模型的 Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "targets should not be none when in training mode",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlr, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m bestMod,train_logs\u001b[38;5;241m=\u001b[39m\u001b[43mtrain_val_for_det\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbestMod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbestMod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_logs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_logs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m            \u001b[49m\u001b[43mshow_progress_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m            \u001b[49m\u001b[43mAMP\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAMP\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#是否使用混合精度训练\u001b[39;49;00m\n\u001b[0;32m     24\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmulti_loss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr_scheduler_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;66;43;03m#动态调整学习率\u001b[39;49;00m\n\u001b[0;32m     26\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# num_epochs=config.epochs\u001b[39;49;00m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Desktop\\DeepLearning\\12.XMU-Review\\MyDLUtils\\Project\\utils\\train_val_for_det.py:274\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, criterion, optimizer, train_loader, val_loader, bestMod, train_logs, config, metrics_weights, num_epochs, checkpoint_interval, show_progress_interval, AMP, multi_loss_weight, lr_scheduler_step)\u001b[0m\n\u001b[0;32m    267\u001b[0m     lr_scheduler \u001b[38;5;241m=\u001b[39m ReduceLROnPlateau(\n\u001b[0;32m    268\u001b[0m         optimizer, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m, factor\u001b[38;5;241m=\u001b[39mlr_scheduler_step, \n\u001b[0;32m    269\u001b[0m         patience\u001b[38;5;241m=\u001b[39mfinal_checkpoint_interval, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    270\u001b[0m     )\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_epochs), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m训练检测模型的 Epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;66;03m# 训练阶段\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m     epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch_detection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    276\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_loss_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_loss_weight\u001b[49m\n\u001b[0;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;66;03m# 验证阶段\u001b[39;00m\n\u001b[0;32m    284\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m validate_model_detection(\n\u001b[0;32m    285\u001b[0m         model, \n\u001b[0;32m    286\u001b[0m         val_loader, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    290\u001b[0m         multi_loss_weight\u001b[38;5;241m=\u001b[39mmulti_loss_weight\n\u001b[0;32m    291\u001b[0m     )\n",
      "File \u001b[1;32md:\\Desktop\\DeepLearning\\12.XMU-Review\\MyDLUtils\\Project\\utils\\train_val_for_det.py:62\u001b[0m, in \u001b[0;36mtrain_one_epoch_detection\u001b[1;34m(model, criterion, optimizer, train_loader, device, scaler, multi_loss_weight)\u001b[0m\n\u001b[0;32m     60\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast(enabled\u001b[38;5;241m=\u001b[39muse_amp):\n\u001b[1;32m---> 62\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;66;03m# 如果输出为多个loss，则用 multi_loss_weight 组合，否则直接计算 loss\u001b[39;00m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(outputs, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\mmdetection\\lib\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\mmdetection\\lib\\site-packages\\torchvision\\models\\detection\\generalized_rcnn.py:62\u001b[0m, in \u001b[0;36mGeneralizedRCNN.forward\u001b[1;34m(self, images, targets)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 62\u001b[0m         \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtargets should not be none when in training mode\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m target \u001b[38;5;129;01min\u001b[39;00m targets:\n",
      "File \u001b[1;32me:\\Anaconda3\\envs\\mmdetection\\lib\\site-packages\\torch\\__init__.py:1209\u001b[0m, in \u001b[0;36m_assert\u001b[1;34m(condition, message)\u001b[0m\n\u001b[0;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(condition) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;129;01mand\u001b[39;00m has_torch_function((condition,)):\n\u001b[0;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(_assert, (condition,), condition, message)\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m condition, message\n",
      "\u001b[1;31mAssertionError\u001b[0m: targets should not be none when in training mode"
     ]
    }
   ],
   "source": [
    "\n",
    "bestMod=utils.BestSelector(acc=0)\n",
    "train_logs=utils.Logs()\n",
    "model=get_pretrained()\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.BCELoss()\n",
    "if config.optim == \"Adam\":\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config.lr)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(), lr=config.lr, momentum=0.9, weight_decay=1e-4)\n",
    "    \n",
    "bestMod,train_logs=train_val_for_det.train_model(\n",
    "            model, \n",
    "            criterion,\n",
    "            optimizer, \n",
    "            train_loader,\n",
    "            val_loader,\n",
    "            bestMod=bestMod,\n",
    "            train_logs=train_logs,\n",
    "            config=config, \n",
    "            checkpoint_interval=10,\n",
    "            show_progress_interval=3,\n",
    "            AMP=config.AMP,#是否使用混合精度训练\n",
    "            multi_loss_weight=[1,0.3,0.3],\n",
    "            lr_scheduler_step=0.7,#动态调整学习率\n",
    "            # num_epochs=config.epochs\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 epoch中 最好的模型\n",
      "acc : 0.5748 ,loss : 1.0468 ,precision : 0.5797 ,recall : 0.5726 ,ap : 0.0915 ,epoch : 27 \n"
     ]
    }
   ],
   "source": [
    "print(f\"{config.epochs} epoch中 最好的模型\")\n",
    "print(bestMod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存模型超参数和训练日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_weights\\MobileNetV-acc=0.5748-loss=1.047-max_epochs=200\n",
      "{'acc': 0.5748, 'model': 'save_weights\\\\MobileNetV-acc=0.5748-loss=1.047-max_epochs=200\\\\best.pth', 'loss': 1.046791520611993, 'precision': 0.5797411973688208, 'recall': 0.5725587596346459, 'ap': 0.09154744311197122, 'epoch': 27, 'checkpoints': {'checkpoint_0': 'save_weights\\\\MobileNetV-acc=0.5748-loss=1.047-max_epochs=200\\\\checkpoint_0.pth'}}\n"
     ]
    }
   ],
   "source": [
    "saveDir=r'save_weights'\n",
    "saveDir=os.path.join(\n",
    "        saveDir,\n",
    "        f'{bestMod.model.__class__.__name__[:10]}-acc={round(bestMod.acc,5)}-loss={round(bestMod.loss,3)}-max_epochs={config.epochs}'\n",
    ")  \n",
    "utils.saveProcess(\n",
    "    saveDir=saveDir,\n",
    "    bestMod=bestMod,\n",
    "    train_log=train_logs,\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "模型测试中:: 100%|██████████| 16/16 [00:01<00:00, 11.48it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Accuracy': 0.6255,\n",
       " 'Precision': 0.6261924414212041,\n",
       " 'Recall': 0.6238458165625979,\n",
       " 'F1': 0.6176151310374951,\n",
       " 'AP': 0.0799395743929934,\n",
       " 'Loss': 1.109235592186451}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from utils import utils,train_val\n",
    "import os\n",
    "\n",
    "# config=Config(os.path.join(dir,'config.json'))\n",
    "# model=BestSelector(os.path.join(dir,'metrics.json'))\n",
    "# saveDir=r'save_weights\\BinaryClassificationMobileNetV3Large-acc=0.74336-loss=1.671334-max_epochs=40-1100'\n",
    "Model,config,logs=utils.loadProcess(saveDir=saveDir)\n",
    "metrics=train_val.validate_model(\n",
    "    model=Model.model,\n",
    "    val_loader=test_loader,\n",
    "    device=config.device,\n",
    "    only_val=True,\n",
    "    criterion=criterion\n",
    ")\n",
    "\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存数据到tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import metrics,utils\n",
    "recoder=metrics.TensorboardRecorder(#存到tensorboard显示\n",
    "    log_dir=\"runs/\",\n",
    "    input_shape=[4,3,128,128],\n",
    "    model=model\n",
    "\n",
    ")\n",
    "recoder.logs_scalars(\n",
    "    logs.logs,\n",
    "    prefix=\"train\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmdetection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
